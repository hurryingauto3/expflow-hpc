#!/usr/bin/env python3
"""
NAVSIM Cache Builder - Example implementation using ExpFlow cache framework

This demonstrates how to extend BaseCacheBuilder for project-specific cache building.

Usage:
    # Create training cache
    builder = NavsimCacheBuilder()
    builder.create_cache_config(
        cache_name="training_cache_ijepa_v4_6cams",
        cache_type="training",
        description="Training cache for I-JEPA v4 with 6 cameras",
        agent="ijepa_planning_agent_v4",
        num_cams=6,
        vision_views=["cam_l0", "cam_f0", "cam_r0", "cam_l1", "cam_r1", "cam_b0"],
        train_split="navtrain"
    )

    # Run full pipeline: build → squashfs → cleanup
    builder.build_cache_pipeline("training_cache_ijepa_v4_6cams")

    # Or step-by-step:
    builder.build_cache("training_cache_ijepa_v4_6cams")
    builder.squashfs_cache("training_cache_ijepa_v4_6cams")
    builder.cleanup_cache("training_cache_ijepa_v4_6cams")

    # Create metric cache
    builder.create_cache_config(
        cache_name="navhard_metric_cache",
        cache_type="metric",
        description="Metric cache for navhard split",
        eval_split="navhard_two_stage",
        partition="cpu",  # Metric caching is CPU-only
        num_cpus=128
    )
    builder.build_cache_pipeline("navhard_metric_cache")
"""

import argparse
import sys
from pathlib import Path

from expflow import BaseCacheBuilder, CacheConfig, load_project_config


class NavsimCacheBuilder(BaseCacheBuilder):
    """
    Cache builder for NAVSIM experiments.

    Supports two cache types:
    1. Training cache: Dataset feature extraction
    2. Metric cache: PDM score metric precomputation
    """

    def __init__(self):
        """Initialize NAVSIM cache builder"""

        # Load HPC config from current project
        try:
            hpc_config = load_project_config()
        except FileNotFoundError:
            print("Error: Not in a project directory.")
            print("Run 'expflow init' first or specify project_root")
            sys.exit(1)

        super().__init__(hpc_config)

        # NAVSIM-specific paths
        self.navsim_devkit_root = Path(f"/scratch/{hpc_config.username}/navsim/navsim_vit_integration")
        self.openscene_data_root = Path(f"/scratch/{hpc_config.username}/data")
        self.nuplan_maps_root = Path(f"/scratch/{hpc_config.username}/data/maps")
        self.navsim_exp_root = Path(f"/scratch/{hpc_config.username}/experiments")

        # Note: Overlays are stored in experiments/cache/overlays (not /scratch/USER/overlays)
        # This keeps all cache-related files organized under experiments/cache/

    def _generate_cache_build_script(self, config: CacheConfig) -> str:
        """
        Generate cache building script for NAVSIM.

        Handles both training and metric caches.
        """

        if config.cache_type == "training":
            return self._generate_training_cache_script(config)
        elif config.cache_type == "metric":
            return self._generate_metric_cache_script(config)
        else:
            raise ValueError(f"Unknown cache type: {config.cache_type}")

    def _generate_training_cache_script(self, config: CacheConfig) -> str:
        """Generate training cache building script"""

        # Extract NAVSIM-specific parameters
        agent = config.cache_params.get("agent", "ijepa_planning_agent_v4")
        backbone = config.cache_params.get("backbone", "ijepa")
        train_split = config.cache_params.get("train_split", "navtrain")
        num_cams = config.cache_params.get("num_cams", 6)
        vision_views = config.cache_params.get(
            "vision_views",
            ["cam_l0", "cam_f0", "cam_r0", "cam_l1", "cam_r1", "cam_b0"]
        )

        # Format vision views for Hydra
        vision_views_str = str(vision_views).replace("'", "").replace(" ", "")

        cache_dir = config.cache_output_dir

        script = f'''#!/bin/bash
# =============================================================================
# HIGH-PERFORMANCE CACHE BUILDING SCRIPT - Auto-generated by ExpFlow
# Cache building is CPU-bound (feature extraction) and I/O-bound (disk writes)
# GPUs are NOT used during caching - they're only used during training!
# =============================================================================
# Cache: {config.cache_name}
# Type: {config.cache_type}
# Description: {config.description}
# Generated: {config.created_at}
# =============================================================================

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task={config.num_cpus}
#SBATCH --mem={config.memory}
#SBATCH --time={config.time_limit}
#SBATCH --job-name=cache_{config.cache_name[:20]}
#SBATCH --account={config.account}
#SBATCH --output={self.logs_dir}/caching/build_{config.cache_name}_%j.out
#SBATCH --error={self.logs_dir}/caching/build_{config.cache_name}_%j.err

# NO GPU - Cache building doesn't use GPUs!
#SBATCH --partition={config.partition}

echo "=============================================="
echo "Building NAVSIM Training Cache (CPU-Optimized)"
echo "=============================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_JOB_NODELIST"
echo "CPUs: $SLURM_CPUS_PER_TASK"
echo "Cache: {config.cache_name}"
echo "Note: Cache building is CPU/IO bound, GPUs not needed"
echo "=============================================="
echo ""

# Environment setup
export HYDRA_FULL_ERROR=1
export NAVSIM_DEVKIT_ROOT="{self.navsim_devkit_root}"
export OPENSCENE_DATA_ROOT="{self.openscene_data_root}"
export NUPLAN_MAPS_ROOT="{self.nuplan_maps_root}"
export NAVSIM_EXP_ROOT="{self.navsim_exp_root}"

# Cache parameters
export AGENT="{agent}"
export BACKBONE="{backbone}"
export TRAIN_SPLIT="{train_split}"
export NUM_WORKERS={config.num_workers}
export FORCE_REBUILD={"true" if config.force_rebuild else "false"}
export NUM_CAMS={num_cams}
export VISION_VIEWS="{vision_views_str}"

# Cache directory
export CACHE_DIR="{cache_dir}"
mkdir -p "$CACHE_DIR"
echo "Cache directory: $CACHE_DIR"
echo ""

cd "${{NAVSIM_DEVKIT_ROOT}}"

# Load conda environment
CONDA_ROOT="/scratch/{self.hpc_config.username}/miniconda3"
if [ -f "${{CONDA_ROOT}}/etc/profile.d/conda.sh" ]; then
    source "${{CONDA_ROOT}}/etc/profile.d/conda.sh"
    conda activate navsim
else
    module purge || true
    module load anaconda3/2025.06 || true
    if command -v conda &> /dev/null; then
        source $(conda info --base)/etc/profile.d/conda.sh || true
        conda activate navsim || source activate navsim || true
    else
        echo "ERROR: conda not found"
        exit 1
    fi
fi

export PYTHONPATH="${{NAVSIM_DEVKIT_ROOT}}:${{PYTHONPATH:-}}"

# Verify environment
echo "Environment check:"
echo "  Python: $(which python)"
echo "  PyTorch: $(python -c 'import torch; print(torch.__version__)' 2>/dev/null || echo 'Not Found')"
echo "  Workers: ${{NUM_WORKERS}}"
echo ""

echo "Starting cache build at $(date)"
echo "Using ${{NUM_WORKERS}} CPU workers for parallel caching..."
echo ""

# Run the dataset caching script
python "${{NAVSIM_DEVKIT_ROOT}}/navsim/planning/script/run_dataset_caching.py" \\
    agent=${{AGENT}} \\
    agent.use_multi_camera=true \\
    agent.vision_views=${{VISION_VIEWS}} \\
    train_test_split=${{TRAIN_SPLIT}} \\
    cache_path="${{CACHE_DIR}}" \\
    force_cache_computation=${{FORCE_REBUILD}} \\
    experiment_name="cache_build_{config.cache_name}" \\
    worker=ray_distributed_no_torch \\
    worker.threads_per_node=${{NUM_WORKERS}}

CACHE_STATUS=$?

echo ""
echo "=============================================="
if [ $CACHE_STATUS -eq 0 ]; then
    echo "Cache build completed successfully at $(date)"
    echo ""
    echo "Cache statistics:"
    du -sh "$CACHE_DIR"
    echo "Files created:"
    find "$CACHE_DIR" -type f -name "*.gz" | wc -l
    echo ""
    echo "Next steps:"
    echo "  1. Compress to SquashFS: python navsim_cache_builder.py squashfs {config.cache_name}"
    echo "  2. Or run full pipeline: python navsim_cache_builder.py pipeline {config.cache_name}"
else
    echo "Cache build FAILED with exit code $CACHE_STATUS"
    echo "Check error log at: {self.logs_dir}/caching/build_{config.cache_name}_${{SLURM_JOB_ID}}.err"
fi
echo "=============================================="

exit $CACHE_STATUS
'''
        return script

    def _generate_metric_cache_script(self, config: CacheConfig) -> str:
        """Generate metric cache building script"""

        eval_split = config.cache_params.get("eval_split", "navhard_two_stage")
        cache_dir = config.cache_output_dir

        script = f'''#!/bin/bash
# =============================================================================
# NAVSIM Metric Cache Builder - Auto-generated by ExpFlow
# Fast parallel metric caching (CPU-only, no GPU needed)
# =============================================================================
# Cache: {config.cache_name}
# Type: {config.cache_type}
# Description: {config.description}
# Generated: {config.created_at}
# =============================================================================

#SBATCH --job-name=cache_{config.cache_name[:20]}
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task={config.num_cpus}
#SBATCH --account={config.account}
#SBATCH --mem={config.memory}
#SBATCH --time={config.time_limit}
#SBATCH --partition={config.partition}
#SBATCH --output={self.logs_dir}/caching/build_{config.cache_name}_%j.out
#SBATCH --error={self.logs_dir}/caching/build_{config.cache_name}_%j.err

echo "=============================================="
echo "Parallel Metric Caching: {eval_split}"
echo "=============================================="
echo "CPUs: $SLURM_CPUS_PER_TASK"
echo "Node: $SLURM_NODE_NAME"
echo "Job ID: $SLURM_JOB_ID"
echo "=============================================="
echo ""

# Environment setup
export NAVSIM_DEVKIT_ROOT="{self.navsim_devkit_root}"
export OPENSCENE_DATA_ROOT="{self.openscene_data_root}"
export NUPLAN_MAPS_ROOT="{self.nuplan_maps_root}"
export NAVSIM_EXP_ROOT="{self.navsim_exp_root}"
export EVAL_SPLIT="{eval_split}"
export CACHE_DIR="{cache_dir}"

mkdir -p "$CACHE_DIR"

cd "${{NAVSIM_DEVKIT_ROOT}}"

# Load conda
CONDA_ROOT="/scratch/{self.hpc_config.username}/miniconda3"
if [ -f "${{CONDA_ROOT}}/etc/profile.d/conda.sh" ]; then
    source "${{CONDA_ROOT}}/etc/profile.d/conda.sh"
    conda activate navsim
else
    module purge || true
    module load anaconda3/2025.06 || true
    if command -v conda &> /dev/null; then
        source $(conda info --base)/etc/profile.d/conda.sh || true
        conda activate navsim || source activate navsim || true
    else
        echo "ERROR: conda not found"
        exit 1
    fi
fi

export PYTHONPATH="${{NAVSIM_DEVKIT_ROOT}}:${{PYTHONPATH:-}}"
export HYDRA_FULL_ERROR=1

echo "Using Python: $(which python)"
echo "Python version: $(python --version)"
echo ""

# Run metric caching
python "${{NAVSIM_DEVKIT_ROOT}}/navsim/planning/script/run_metric_caching.py" \\
    train_test_split="${{EVAL_SPLIT}}" \\
    metric_cache_path="${{CACHE_DIR}}" \\
    worker=ray_distributed_no_torch \\
    max_number_of_workers={config.num_workers}

CACHE_STATUS=$?

echo ""
echo "=============================================="
if [ $CACHE_STATUS -eq 0 ]; then
    echo "Metric caching complete!"
    echo "Cache saved to: ${{CACHE_DIR}}"
    echo ""
    du -sh "$CACHE_DIR"
    echo ""
    echo "Next steps:"
    echo "  1. Compress: python navsim_cache_builder.py squashfs {config.cache_name}"
    echo "  2. Cleanup: python navsim_cache_builder.py cleanup {config.cache_name}"
else
    echo "Metric caching FAILED with exit code $CACHE_STATUS"
fi
echo "=============================================="

exit $CACHE_STATUS
'''
        return script

    def get_cache_script_command(self, config: CacheConfig) -> str:
        """
        Get the Python command for cache building.

        This is used for documentation and dry-run preview.
        """
        if config.cache_type == "training":
            agent = config.cache_params.get("agent", "ijepa_planning_agent_v4")
            split = config.cache_params.get("train_split", "navtrain")
            return f"python run_dataset_caching.py agent={agent} train_test_split={split}"
        elif config.cache_type == "metric":
            split = config.cache_params.get("eval_split", "navhard_two_stage")
            return f"python run_metric_caching.py train_test_split={split}"
        else:
            return "Unknown cache type"


# =============================================================================
# CLI
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="NAVSIM Cache Builder - ExpFlow Integration",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Create training cache config
  python navsim_cache_builder.py new training_cache_v4_6cams \\
      --type training \\
      --agent ijepa_planning_agent_v4 \\
      --num-cams 6 \\
      --description "Training cache for I-JEPA v4 with 6 cameras"

  # Create metric cache config
  python navsim_cache_builder.py new navhard_metric_cache \\
      --type metric \\
      --eval-split navhard_two_stage \\
      --description "Metric cache for navhard evaluation"

  # Build cache (step 1)
  python navsim_cache_builder.py build training_cache_v4_6cams

  # Compress to SquashFS (step 2)
  python navsim_cache_builder.py squashfs training_cache_v4_6cams

  # Cleanup original directory (step 3)
  python navsim_cache_builder.py cleanup training_cache_v4_6cams

  # Or run full pipeline (all 3 steps with dependencies)
  python navsim_cache_builder.py pipeline training_cache_v4_6cams

  # List caches
  python navsim_cache_builder.py list
  python navsim_cache_builder.py list --type training

  # Show details
  python navsim_cache_builder.py show training_cache_v4_6cams
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # new
    new_parser = subparsers.add_parser("new", help="Create new cache config")
    new_parser.add_argument("cache_name", help="Cache name")
    new_parser.add_argument("--type", choices=["training", "metric"], required=True,
                           help="Cache type")
    new_parser.add_argument("--description", "-d", default="", help="Description")
    new_parser.add_argument("--agent", default="ijepa_planning_agent_v4",
                           help="Agent (for training cache)")
    new_parser.add_argument("--backbone", default="ijepa", help="Backbone")
    new_parser.add_argument("--train-split", default="navtrain", help="Training split")
    new_parser.add_argument("--eval-split", default="navhard_two_stage",
                           help="Eval split (for metric cache)")
    new_parser.add_argument("--num-cams", type=int, default=6, help="Number of cameras")
    new_parser.add_argument("--vision-views", nargs="+",
                           default=["cam_l0", "cam_f0", "cam_r0", "cam_l1", "cam_r1", "cam_b0"],
                           help="Vision views")
    new_parser.add_argument("--partition", default="cpu", help="SLURM partition")
    new_parser.add_argument("--num-cpus", type=int, default=128, help="CPUs")
    new_parser.add_argument("--memory", default="256G", help="Memory")
    new_parser.add_argument("--num-workers", type=int, default=96, help="Data workers")

    # build
    build_parser = subparsers.add_parser("build", help="Build cache")
    build_parser.add_argument("cache_name", help="Cache name")
    build_parser.add_argument("--dry-run", action="store_true", help="Show script but don't submit")
    build_parser.add_argument("--wait-for", help="Wait for job ID")

    # squashfs
    squashfs_parser = subparsers.add_parser("squashfs", help="Compress to SquashFS")
    squashfs_parser.add_argument("cache_name", help="Cache name")
    squashfs_parser.add_argument("--dry-run", action="store_true", help="Show script but don't submit")
    squashfs_parser.add_argument("--wait-for", help="Wait for job ID")

    # cleanup
    cleanup_parser = subparsers.add_parser("cleanup", help="Cleanup original cache")
    cleanup_parser.add_argument("cache_name", help="Cache name")
    cleanup_parser.add_argument("--dry-run", action="store_true", help="Show script but don't submit")
    cleanup_parser.add_argument("--wait-for", help="Wait for job ID")

    # pipeline
    pipeline_parser = subparsers.add_parser("pipeline", help="Run full pipeline")
    pipeline_parser.add_argument("cache_name", help="Cache name")
    pipeline_parser.add_argument("--skip-squashfs", action="store_true",
                                help="Skip SquashFS compression")
    pipeline_parser.add_argument("--skip-cleanup", action="store_true",
                                help="Skip cleanup")
    pipeline_parser.add_argument("--dry-run", action="store_true",
                                help="Show scripts but don't submit")

    # list
    list_parser = subparsers.add_parser("list", help="List caches")
    list_parser.add_argument("--type", choices=["training", "metric"], help="Filter by type")

    # show
    show_parser = subparsers.add_parser("show", help="Show cache details")
    show_parser.add_argument("cache_name", help="Cache name")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    builder = NavsimCacheBuilder()

    if args.command == "new":
        cache_params = {}
        if args.type == "training":
            cache_params = {
                "agent": args.agent,
                "backbone": args.backbone,
                "train_split": args.train_split,
                "num_cams": args.num_cams,
                "vision_views": args.vision_views,
            }
        elif args.type == "metric":
            cache_params = {
                "eval_split": args.eval_split,
            }

        builder.create_cache_config(
            cache_name=args.cache_name,
            cache_type=args.type,
            description=args.description,
            partition=args.partition,
            num_cpus=args.num_cpus,
            memory=args.memory,
            num_workers=args.num_workers,
            cache_params=cache_params
        )

    elif args.command == "build":
        builder.build_cache(args.cache_name, dry_run=args.dry_run, wait_for=args.wait_for)

    elif args.command == "squashfs":
        builder.squashfs_cache(args.cache_name, dry_run=args.dry_run, wait_for=args.wait_for)

    elif args.command == "cleanup":
        builder.cleanup_cache(args.cache_name, dry_run=args.dry_run, wait_for=args.wait_for)

    elif args.command == "pipeline":
        job_ids = builder.build_cache_pipeline(
            args.cache_name,
            skip_squashfs=args.skip_squashfs,
            skip_cleanup=args.skip_cleanup,
            dry_run=args.dry_run
        )
        if not args.dry_run:
            print("\nPipeline submitted:")
            for stage, job_id in job_ids.items():
                if job_id:
                    print(f"  {stage}: {job_id}")

    elif args.command == "list":
        builder.list_caches(cache_type=args.type)

    elif args.command == "show":
        builder.show_cache(args.cache_name)


if __name__ == "__main__":
    main()
